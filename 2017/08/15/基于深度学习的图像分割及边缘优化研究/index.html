<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8" />
  
  <title>基于深度学习的图像分割 | Now You See Me!</title>
  <meta name="author" content="Now You See Me!" />

  
  <meta name="description" content="摘要 近几年来，借助于深度学习，机器视觉的发展越来越迅速。图像分割是机器视觉中的关键技术。为了更好地理解和分析图像，我们需要将图像中的关键内容从图像中抽离出来，这就是图像分割问题。更准确地说，图像分割就是将图像中的每一个像素进行再分配的过程，使得具有相同标签的像素点具有某一些特征。图像分割是图像理解" />
  

  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

  <meta property="og:title" content="基于深度学习的图像分割" />
  <meta property="og:site_name" content="Now You See Me!" />

  
  

  
    <meta property="og:image" content="" />
  

  
  <link href="/css/images/favicon.ico" rel="icon" />
  

  <link rel="alternate" href="/atom.xml" title="Now You See Me!" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


  <!-- baidu webmaster push -->
  <script src='//push.zhanzhang.baidu.com/push.js'></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Now You See Me!</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/archives/">所有文章</a></li>
    
      <li><a href="/categories/编程感悟">编程感悟</a></li>
    
      <li><a href="/categories/算法">算法之道</a></li>
    
      <li><a href="/categories/Java">Java</a></li>
    
      <li><a href="/categories/Python">Python</a></li>
    
      <li><a href="/categories/Linux">Linux</a></li>
    
      <li><a href="/categories/机器学习">机器学习</a></li>
    
      <li><a href="/categories/技能树">Other</a></li>
    
      <li><a href="/categories/兴趣爱好">兴趣爱好</a></li>
    
      <li><a href="/categories/个人生活">我的生活</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-08-15T14:39:48.000Z"><a href="/2017/08/15/基于深度学习的图像分割及边缘优化研究/">2017-08-15</a></time>
      
      
  
    <h1 class="title">基于深度学习的图像分割</h1>
  

    </header>
    <div class="entry">
      
        <h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p> 近几年来，借助于深度学习，机器视觉的发展越来越迅速。图像分割是机器视觉中的关键技术。为了更好地理解和分析图像，我们需要将图像中的关键内容从图像中抽离出来，这就是图像分割问题。更准确地说，图像分割就是将图像中的每一个像素进行再分配的过程，使得具有相同标签的像素点具有某一些特征。图像分割是图像理解、图像识别等诸多图像处理任务中的重要一环，图像分割在自动驾驶、视频监控和医疗图像等领域中有着广泛的应用。在现实应用中，图像分割的分割结果容易受到复杂背景的影响，比如光照、阴影、遮挡等。因此，一个良好的图像分割算法具有重要的现实意义。</p>
<p> 传统的图像分割算法大部分都是基于图像本身的特征提取，这些方法大多都是根据像素特征先将原图分割成多个小区域，然后计算每一个区域的特征，最后进行区域合并。这些分割算法没有一种是自适应且普遍适用的分割算法，大多难以取得令人满意的分割效果。由于卷积神经网络具有良好的特征提取能力，如何把卷积神经网络应用到图像分割任务上也是当前研究的一大热点。事实证明，卷积神经网络在图像分割中能取得的分割结果比传统图像分割算法更加良好。但是在图像卷积过程中，图像会丢失部分边缘信息，导致最后分割边缘模糊。</p>
<p> 本文在图像分割算法和深度学习的理论基础上，研究如何基于卷积神经网络，然后采用边缘优化算法解决图像分割问题。论文的主要工作和创新点在于：<br> （1）针对自然场景图像，使用全卷积神经网络分割模型。采用两阶段的模型训练方法，训练并优化模型。直接对自然场景图像在像素水平上进行预测其所属的语义类别。全卷积网络是仅有卷积层和反卷积层的网络模型，卷积层用于提取分割特征，反卷积层把分割特征恢复到原图一致大小。在图像分割领域，全卷积网络被证明能达到较好的分割效果。<br> （2）提出全卷积网络和双边滤波器相结合的分割方法。全卷积网络分割模型对原图进行特征提取得到像素水平的概率分布的特征，再使用双边滤波器对图像进行边缘处理。双边滤波器是一种非线性滤波，是结合图像的空间邻近度和像素值相似度的一种滤波器。双边滤波器的作用就是边缘保存，能对全卷积网络模型处理后的模糊边缘进一步优化分割。<br> （3）提出全卷积网络和K-means聚类算法相结合的分割方法。K-means聚类算法是一种距离相似性的聚类算法，通过比较像素值之间的相似性，将像素点划分到相同或者不同的类别中。图像分割的本质是一种像素的聚类过程，因此K-means能对图像达到过分割的效果。通过把全卷积神经网络分割模型得到的粗分割结果与K-means得到的过分割结果进行像素点匹配，对粗分割的模糊边缘的像素点进行进一步分类，提高分类精度。<br> （4）将本文提出的算法模型应用到人体分割领域。使用两阶段训练法，训练并优化模型，把模型应用于人体图像，取得了接近真值的效果。<br>关键字：图像分割、全卷积网络、双边滤波器、K-means</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="第1章-绪论"><a href="#第1章-绪论" class="headerlink" title="第1章 绪论"></a>第1章 绪论</h2><h3 id="研究背景和意义"><a href="#研究背景和意义" class="headerlink" title="研究背景和意义"></a>研究背景和意义</h3><p>人们在现实生活中主要是通过语音、文本和图像这三种渠道来获取外界信息。图像是最快捷且最具有表现力的渠道，然而图像也是最复杂的表现渠道。在一幅图像中，人们往往关注的并不是整幅图所有的内容，而是当中的某一个区域。在计算机视觉的研究和应用中，我们往往需要着重研究这些具有特殊性质的区域，人们一般称之为前景或目标区域，除前景以外的所有的区域我们称之为背景或非目标区域。为了理解、分析和识别这些目标区域，需要将前景从图像中选取出来，即图像分割问题。图像分割技术已经在机器人技术、医学诊断、卫星图像分析、自动驾驶中广泛应用。在这些领域中，图像分割只是当中的一个基本任务之一，确实非常重要的一环。图像分割有针对性地提取前景，有助于图像理解和图像分析。由于图像分割结果的好坏直接影响到后续任务，因此图像分割算法的研究一直都很受研究者的重视。在医疗诊断领域，由于癌变细胞比较小，因此对分割模型的分割精度要求比较高。在自动驾驶领域，则要求模型的分割速度要达到实时。</p>
<p>图像分割是利用图像内部的某些特征对图像的像素点进行再次聚类的过程，最终把图像分割中若干个互不重叠的区域，且每一个区域都具有灰度、内容和纹理的相似性，且每一个区域的内部都是比较平整的，而不同的区域之间有着显著的特征差异。由于图像分割的应用具有普遍性，到目前为止，研究者们已经提出了大量的图像分割算法，但是这些算法大多具有局限性。从比较直观的角度来评价一个好的图像分割算法应该具备以下特性：①一个区域的内容应代表一个语义②不同语义的边界应该是明确且规整的。在实际应用当中，图像分割算法很容易受到复杂背景以及光照、遮挡等因素的影响，因此图像分割任务一直面临着很多困难和挑战。当图像中的前景和背景中的物体在轮廓特征上较为相似，则分割算法很难准确地将前景和背景区分开来；当前景中的物体受到遮挡，遮挡物是另一个前景或者背景时，分割算法的效果也会受到干扰。尤其是在多目标分割时，前景中若存在多个不同的物体，分割算法则有可能会将部分边缘像素点错误分类。这些都是目前图像分割算法面临的困难，且没有一种普适的算法能够解决这些问题。</p>
<p>尽管图像分割目前已经取得了良好的进步，但是由于图像分割任务自身的复杂性，越来越多的研究者致力于把新的算法引进图像分割领域，来达到更好地分割效果，且能适应不同的任务场景。</p>
<h3 id="发展及研究现状"><a href="#发展及研究现状" class="headerlink" title="发展及研究现状"></a>发展及研究现状</h3><h4 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h4><p>图像分割技术有很多不同的定义，从模式识别的角度来讲，图像分割就是根据图像中的像素信息对像素点进行聚类，把图像划分成若干个互不重叠的子区域，这些子区域可以是前景也可以是背景，同一子区域具有相同的语义标签，代表着同一个物体，不同的子区域之间的差异性很大。从数学的角度来讲，图像分割就是将一个集合分成若干个互不重叠的子集。</p>
<p>借助于像素集合的观点，把图像所有的像素点定义为集合$R$, 则图像分割就是要将图像分割成若干个互不重叠的非空子集$R_1$, $R_2$, $R_3$,…,$R_n$。这些非空子集必须满足一下条件：</p>
<p>（1）对于$i=1,2,3…N$, $\bigcup_{i=1}^{N}R_i = R$,所有的非空子集合并等于图像所代表的全集;<br>（2）对于$i, j=1,2,3…N$, 任意的$i\not= j$, $S_i \bigcap S_j = \phi$, 即任意两个不一样的区域没有重叠的像素点;<br>（3）$i=1,2,3…N$, $P(R_i) = True$, 即同一个区域的像素点具有相似性；<br>（4）$i, j=1,2,3…N$，$P(R_i) \bigcap P(R_j) = False$, 即不同的区域像素点具有显著区别；<br>（5）$i=1,2,3…N$， $R_i$是连通的。<br>以上这五个概念不仅能对图像分割的概念进行解释，同时也是图像分割任务中依据的标准。</p>
<h4 id="常用的图像分割方法"><a href="#常用的图像分割方法" class="headerlink" title="常用的图像分割方法"></a>常用的图像分割方法</h4><p>自上世纪七八十年代开始，图像分割领域开始受到广大研究者的重视，这么多年以来，针对不同的图像分割场景，研究者们提出了不同的分割方法。然而，由于图像分割任务的场景非常复杂，且干扰因素非常多，所以到目前为止并没有一种普适的方法能通用于不同的领域并取得不错的分割效果。根据具体的情况不同，往往在分割中使用的方法也不同，尤其是近年来，越累越多的新方法和新思路被引入到图像分割领域。本文通过充分的调研，将目前目前主流的图像分割方法分为四种，即基于阈值的图像分割方法、基于边缘的图像分割方法、基于区域的图像分割方法和基于聚类的图像分割方法。</p>
<p><strong>（1）基于阈值的图像分割方法</strong><br>阈值法的思路就是根据整张图像像素的灰度值来得到一个合适的阈值$I$，再将图像中每个像素值得灰度值与阈值$I$做对比，然后根据每个像素点比较得到的结果再次将像素点归类，从而达到图像分割的效果。常见的基于阈值的图像分割方法有：直方图双峰法、固定阈值分割、半阈值分割、迭代阈值分割、自适应阈值图像分割等。寻找一个合适的灰度值是阈值分割算法中最关键的一步。然而，在实际应用中，阈值的设定受到例如光照、阴影以及图像内容的影响，并不存在一个普适的阈值选取方法能让每一个应用场景达到一个好的分割效果。目前已经存在阈值选取方法有：方差法、双峰法、基于图像拓扑稳定状态方法等。</p>
<p>基于阈值的分割方法的思路最简单的分割方法，算法的计算简单且高效。对于不同目标灰度值差别不大的图像，全局阈值不能有效地将前景和背景分割开来。对待这种图像内部差异不明显的图像，需要采取局部阈值和动态阈值分割方法。由于阈值分割方法只是利用图像的像素值信息进行图像分割，忽略了图像的空间信息，因此很容易收到噪声的干扰。</p>
<p><strong>（2）基于边缘的图像分割方法</strong><br>边缘检测是图像分割的基本方法之一，该方法的计算量比较小，而且具有很好的抗噪性。由于图像边缘像素点的像素值灰度变化比较剧烈，相应的梯度比较大。在各种干扰因素下，通过边缘检测算法依然能够得到较为理想的边缘分割效果。早期的边缘检测算法比较简单，使用带权值的边缘检测算子对图像的每一个像素点做卷积运算，达到突出图像边缘像素点的效果。这种边缘检测分割算法存在大量断裂和冗余问题。随着研究的不断深入，越来越多的边缘检测分割算法被提出来。目前常用的一阶或二阶微分算子进行边缘检测，这些算子有：Sobel算子、Robets算子、拉普拉斯算子等。图像中各区域的边缘是分割的重要基础，此类分割方法的原理就是将相邻的边缘像素点连接起来，以此形成闭合的连通边界，从而完成图像分割。常用的基于边缘的图像分割方法有：边缘检测算子法、多尺度法和图像滤波法等。</p>
<p>基于边缘的图像分割算法的困难和挑战在于如何在检测精度和抗噪性之间做出一个权衡。过高地追求分割精度会导致更多伪边缘的产生；反之，过高地要求抗噪性，那么边缘轮廓的分割精度会受到影响。在实际应用中，需要综合考虑这两方面因素的相互作用。</p>
<p><strong>（3）基于区域的图像分割方法</strong><br>图像中的每一个像素点都是一个独立的像素点，初始状态下，并没有相互连通的状态。从基于区域的角度来看待已分割图像，就是具有相同性质的像素点被连通到了一个连通元中。这种分割方法基于相似性原理吧图像中的每一个像素点进行划分到不同子区域，常见的有分裂合并法和种子生长法。由于基于区域的图像分割方法利用到了局部空间信息，避免了分割区域过小的缺点。分裂合并法是把属性相近的像素点聚集位一个区域，聚集后的小区域很多，然后根据小区域之间的相似性进行区域合并，形成大区域。种子生长法法是把整张图的每一个像素点根据区域属性特征相似的规则来规划每个像素点所属的区域，此方法是从全图出发。分裂合并法和种子生长法的原理刚好相反，前者是从每一个像素点出发，后者是从图像整体开始。</p>
<p>当图像区域的同一性准则容易定义时，这些分裂合并和种子生长法的分割质量较好，且受噪声的影响不大。种子生长法的最大缺陷在于分割效果严重依赖于种子点的选取质量以及生顺序，分裂合并法的缺陷是有可能使分割边界被破坏。实际应用中，分裂合并法和种子生长法经常会被结合使用。基于区域的分割方法在近年来发展迅速，当区域分割方法和机器学习算法相结合，分割效率和精度有了明显的提升。在基于区域的分割方法的基础上，有人提出了交互式分割方法。交互式分割方法能充分弥补空间信息，因此交互式分割方法在图像分割领域取得了非常不错的效果。但是交互式分割方法的最大缺陷就是需要与人工进行交互，不能让独立完成分割。</p>
<p>基于区域的图像分割一直是研究的热门之一，不仅仅在图像分割领域，目标检测领域也会用到基于区域的图像分割方法。不同的应用场景面临着不同的困难和挑战，具体使用哪一种区域分割方法需要视情况而定。综合使用基于区域的图像分割方法和基于边缘的图像分割方法，能取得更好地分割效果。</p>
<p><strong>（4）基于聚类的图像分割方法</strong></p>
<p>近年来，聚类算法被引入图像分割领域。此类方法的主要原理就是将像素点映射到不同区域或者特征空间中，然后据此对图像进行分割。比较常用的两类分割方法为基于特征空间聚类的方法和基于模糊聚类的分割方法。</p>
<p>基于特征空间的聚类方法属于典型的硬划分方法，即对于每一个像素点进行分类，每一个像素点只能属于某一个类，K-means算法是基于特征空间的聚类算法的代表之一。这类分割算法的缺陷就是没有考虑像素点领域之间的关系，如果不增加后续处理过程，很难达到理想的分割效果。</p>
<p>硬划分方法在很多应用场景中并不合适，往往不能取得较好的效果。基模糊聚类的分割算法属于软划分方法，该类分割方法允许像素点能同时隶属于多个不同的聚类当中，使用“隶属度”来 描述该像素点属于与聚类之间的隶属关系。模糊C均值聚类算法就是此类方法的代表。</p>
<p><strong>（5）基于卷积神经网络的图像分割方法</strong><br>深度学习是机器学习的一个分支，主要指卷积神经网络算法。深度学习在图像分类、目标检测和高分辨率图像生成等领域已经取得了突破性的进展。由于卷积神经网络具备良好的提特征能力，因此常被用于进行特征学习。早期的卷积神经网络可用来做图像分类，由于图像分割任务与图像分类任务的差异很大，常用的用于图像分类的网络模型并不能应用到图像分割任务上。</p>
<p>全卷积神经网络是第一个真正意义上把深度神经网络应用到图像分割任务上的网络模型。图像分割任务实质上就是对图像中的像素点进行一对一的映射到标签上，标签即该像素点所属的语义类别。全卷积神经网络相比于卷积神经网络在网络结构上有所不同，全卷积网络的网络模型里只有卷积层和反卷积层。去掉全连接层可以有效留住图像的二维信息。图像在卷积的过程中，特征的尺寸会不断地变小，图像分割的最终结果必须与原图保持大小一致，在卷积层后面，此网络模型使用双线性插值法或者反卷积层将特征映射到原图一致大小。</p>
<p>全卷积神经网络结合卷积层和反卷积层，形成一个端到端的映射器，将原图中的像素点重映射类别，达到分割的目的。网络结构越复杂，分割性能越好。此分割方法不仅能使用复杂背景的图像，而且在多目标分割中取得良好的分割效果。但是该分割方法对于数据集的质量和数量要求比较高。训练集必须提供标记数据，由于像素点标记比较难，所以已经公开的带标记的图像分割数据集都不大。全卷积神经网络的在卷积过程中会丢失原图的边缘信息，从而边缘部分的分割精度在一定程度上受到影响。本文的主要研究对象就是全卷积神经网络算法及其改进算法，达到优化边缘分割的目的。</p>
<h3 id="本文的工作及结构安排"><a href="#本文的工作及结构安排" class="headerlink" title="本文的工作及结构安排"></a>本文的工作及结构安排</h3><h4 id="论文的主要工作"><a href="#论文的主要工作" class="headerlink" title="论文的主要工作"></a>论文的主要工作</h4><p>本文在图像分割算法和深度学习的理论基础上，研究如何基于卷积神经网络，然后采用边缘优化算法解决图像分割问题。论文的主要工作和创新点在于：<br> （1）针对自然场景图像，使用全卷积神经网络分割模型。采用两阶段的模型训练方法，训练并优化模型。直接对自然场景图像在像素水平上进行预测其所属的语义类别。全卷积网络是仅有卷积层和反卷积层的网络模型，卷积层用于提取分割特征，反卷积层把分割特征恢复到原图一致大小。在图像分割领域，全卷积网络被证明能达到较好的分割效果。<br> （2）提出全卷积网络和双边滤波器相结合的分割方法。全卷积网络分割模型对原图进行特征提取得到像素水平的概率分布的特征，再使用双边滤波器对图像进行边缘处理。双边滤波器是一种非线性滤波，是结合图像的空间邻近度和像素值相似度的一种滤波器。双边滤波器的作用就是边缘保存，能对全卷积网络模型处理后的模糊边缘进一步优化分割。<br> （3）提出全卷积网络和K-means聚类算法相结合的分割方法。K-means聚类算法是一种距离相似性的聚类算法，通过比较像素值之间的相似性，将像素点划分到相同或者不同的类别中。图像分割的本质是一种像素的聚类过程，因此K-means能对图像达到过分割的效果。通过把全卷积神经网络分割模型得到的粗分割结果与K-means得到的过分割结果进行像素点匹配，对粗分割的模糊边缘的像素点进行进一步分类，提高分类精度。<br> （4）将本文提出的算法模型应用到人体分割领域。使用两阶段训练法，训练并优化模型，把模型应用于人体图像，取得了接近真值的效果。</p>
<h4 id="论文的结构安排"><a href="#论文的结构安排" class="headerlink" title="论文的结构安排"></a>论文的结构安排</h4><p>为了提高图像分割的正确率，将全卷积神经网络和边缘优化算法结合是一种比较有效的方式。论文的主要内容分为六章，每章的具体安排为：<br>第一章 绪论。主要介绍了课题研究的背景和意义、研究现状以及主要的图像分割方法，并对论文的主要工作和创新点进行说明。<br>第二章<br>第二章 全卷积神经网络的理论基础。重点介绍全卷积神经网络的概念、网络模型的结构，分析全卷积神经网络多层特征融合的作用。描述全卷积神经网络模型的训练方法，对比网络深度对于全卷积神经网络性能的影响。<br>第三章 结合全卷积神经网络和双边滤波器的图像分割。首先介绍双边滤波器对于边缘优化的作用，然后给出双边滤波器能量函数的定义，最后结合双边滤波器给出实验结果证明双边滤波器的有效性。<br>第四章 结合全卷积神经网络和K-means聚类算法的图像分割。本章首先介绍K-means算法在图像分割中的原理，然后给出结合K-means聚类算法优化全卷积神经网络边缘的流程，最后通过结果进行分析该算法的有效性。<br>第五章 结合全卷积神经网络和条件随机场的图像分割。本章首先介绍条件随机场图像分割方法，然后给出条件随机场图像分割模型的能量函数的定义并对其进行最小化进而得到分割结果，最后通过结果证明该方法的有效性。<br>第六章 总结与展望。本章对论文的主要工作和研究内容进行归纳和总结，并对本文仍存在的不足之处进行分析和后续工作方向进行简单分析。</p>
<h4 id="本章小结"><a href="#本章小结" class="headerlink" title="本章小结"></a>本章小结</h4><p>首先本章先介绍了图像分割的背景和现状研究及图像分割在各行各业中的应用，其次介绍了图像分割的相关技术，最后总结了图像分割领域中的各种算法并做出了客观评价。基于现有的图像分割方法，介绍并提出了结合全卷积神经网络和K-means算法的图像分割方法，并描述了本文的主要工作和结构安排。</p>
<h2 id="第2章-全卷积神经网络介绍"><a href="#第2章-全卷积神经网络介绍" class="headerlink" title="第2章 全卷积神经网络介绍"></a>第2章 全卷积神经网络介绍</h2><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>卷积神经网络在目标分类、图像检索和人脸识别领域有着非常出色的表现。在比较短的时间内，卷积神经网络算法就已经推广到了机器学习的各个领域。计算机视觉是卷积神经网络最先突破的领域之一。自从AlextNet取得了ILSVRC比赛的冠军，学者们就开始意识到卷积神经网络算法在机器视觉领域的优越性。卷积神经网络是一种前馈神经网络，神经网络主要由一个或多个卷积层和顶层的全连接层构成，卷积层的作用是特征提取，卷积层由多个人工神经元组成，每一个人工神经元负责感受图像中的一个局部区域。</p>
<center><img src="http://yeshenlin.com/yelin_image/01_paper.png"></center>

<p>一个简单地卷积神经网络结构如图所示，前面的几层都是由卷积层和池化层以组成，卷积层中每一个单元区域对应着一个人工神经单元的感受区域，每一个人工神经单元通过卷积核与这个感受区域相连，卷积核中的参数即是权值。卷积层卷积出的结果是特征图，在特征图中，每一个局部块与上一层特征图的一个局部快相连，通过卷积核中参数的局部加权，计算出的结果传递给一个非线性函数，我们称之为激活函数。由于在图像中，每一个像素点的信息与领域的像素点有关，所以通过非线性激活函数能得到有效的局部特征。<br>卷积层的主要作用就是上一层传递的特征图进行再次特征提取，池化层的作用是降温。池化层在计算特征时，将一个局部区域的像素信息用局部最大值或者平均值代替。全连接层的作用是把前面所有层学习到的特征映射到样本标记空间。最后加上一个分类器层，就形成了一个卷积神经网络分类器。</p>
<h3 id="全卷积神经网络结构"><a href="#全卷积神经网络结构" class="headerlink" title="全卷积神经网络结构"></a>全卷积神经网络结构</h3><p>顾名思义，全卷积神经网络就是所有网络层都是卷积层组成的卷积神经网络。全卷积神经网络对输入的原图通过卷积层进行特征提取，得到多个特征图，通过池化层对特征图进行降维。由于图像分割的结果必须与原图像的大小尺寸保持一致，因此，使用反卷积层和反池化层把卷积结果重新调整到原图一致水平，从而实现了一个端到端的网络结构，该网络把原图中的每一个像素点映射到类别标签。</p>
<center><img src="http://yeshenlin.com/yelin_image/02_paper.png"></center>

<p>如图所示，全卷积神经网络结构主要分为前半部分和后半部分，前半部分的卷积层网络结构与VGG-net类似，区别是全卷积网络去掉了全连接层，后面都是反卷积层。整个端到端的过程简洁有效，没有提前对原图进行区域候选，也没有在反卷积后期对分割区域进行区域合并。</p>
<p>VGG-net的网络结构如所示，通常有16到19层。VGG-net的网络层次比较深，在特征提取上能取得很好的效果，因此图像分类的效果相对于浅层神经网络来说比较好。VGG-net的网络结构如图所示。</p>
<center><img src="http://yeshenlin.com/yelin_image/03_paper.png"></center>

<p>从图中，我们可以看到整个网络的大部分都是卷积层搭配着池化层，在最后一个卷积层后面跟着三个全连接层，全连接层后面接着Softmax层对特征分类，输出输入图像的预测概率值，最后通过比较得到最有可能类别。VGG-net的特点是卷积层中卷积核尺寸都是3乘3，池化层的窗口大小都是2乘2，移动步长为2。目前VGG-net在机器视觉的各类任务中已经体现出非常好的性能表现，说明该网络结构有着良好的特征提取能力，在所有任务中的性能表现主要取决于它的特征提取能力，只要能充分挖掘图像中的特征，才能为各类任务的最后特征分类阶段提供好的条件。</p>
<center><img src="http://yeshenlin.com/yelin_image/04_paper.png"></center>

<p>全卷积网络的结构如图所示，该网络结构在全连接层之前与VGG-net的网络结构一样，去掉了三个全连接层和softmax层，后面增加了反池化和反卷积层的组合。整个网络可以分为卷积网络和反卷积网络两个部分，网络在计算过程中是端到端的，输入一张原图，输出分割结果，没有多余的处理，结构简单且高效。</p>
<h4 id="反卷积层"><a href="#反卷积层" class="headerlink" title="反卷积层"></a>反卷积层</h4><p>卷积运算在图像处理中经常能被用到，在求取一张灰度图的边缘轮廓的时候，我们可以使用canny算子、sobel算子等对输入图像进行卷积，这些算子是正方形卷积模板，相当于特征提取器，卷积运算的结果是图像边缘检测的结果。卷积运算的过程如图所示，卷积运算算是从左上角到右下角一块一块地卷积局部区域。在卷积神经网络中，卷积层中含有较多卷积核，每个卷积核在卷积过程中，提取原图某一个区域的特征，将一张大的原图转化为多个小图。卷积层能保证位移和旋转不变性。</p>
<center><img src="http://yeshenlin.com/yelin_image/05_paper.png"></center>

<p>反卷积运算和卷积运算的原理基本一致，由于全卷积网络中的反池化层会使区域信息变得稀疏，反卷积操作使输出变得密集，且该滤波器是可学习的。全卷积网络中前半部分输出的结果是图像每个像素点概率热图，此概率热图的尺寸比较小，要恢复到原图大小，必须使用反池化操作，但是反池化操作把一个像素点去填充一个卷积区域中的一个像素点，则该区域的其它像素点就没有像素信息，反卷积层可以通过学习卷积核中的参数，把这些稀疏信息填充起来。该反卷积层也可以通过双线性插值来实现，通过把一个像素点周围四领域像素点进行线性计算获得中间像素点的像素值，使用该方法来将小图填充得到与原图一致性大小的输出结果。双线性插值的过程如图所示，假设我们想知道未知函数$f$在$P(x,y)$的值，加入已知$Q_{11}=(x_1, y<em>1)$,$Q</em>{12}=(x_1, y<em>2)$,$Q</em>{21}=(x_2, y<em>1)$及$Q</em>{22}=(x_2, y_2)$这四个点的值。第一步，在x方向上进行线性插值，得到：</p>
<p>$$f(R_1)=\cfrac {x_2-x}{x_2- x<em>1}f(Q</em>{11})+\cfrac {x-x_1}{x_2- x<em>1}f(Q</em>{21})$$<br>$$f(R_2)=\cfrac {x_2-x}{x_2- x<em>1}f(Q</em>{12})+\cfrac {x-x_1}{x_2- x<em>1}f(Q</em>{22})$$</p>
<p>然后在y方向上进行线性插值，得到：</p>
<p>$$f(P)=\cfrac{y_2-y}{y_2-y_1}f(R_1)+\cfrac{y-y_1}{y_2-y_1}f(R_2)$$</p>
<p>然后沿着y方向进行线性插值,就能得到$f(x, y)$</p>
<center><img src="http://yeshenlin.com/yelin_image/06_paper.png"></center>

<center><img src="http://yeshenlin.com/yelin_image/07_paper.png"></center>

<h4 id="反池化层"><a href="#反池化层" class="headerlink" title="反池化层"></a>反池化层</h4><p>池化层的输入时上一个卷积层，其主要作用是对卷积层提取到的特征进行降维，提供了较好的鲁棒性，比如max-pooling的作用就是把一小块区域的像素值信息用该区域中像素值最大的那个像素点进行代替，减少了参数量，在一定程度上起到了防止过拟合的作用，池化层没有卷积参数，因此在反向传播的过程中，不需要对权值进行更新。<br>反卷积层<br>反池化层与池化层的作用刚好相反，如图所示，反池化层是一个上采样过程，是池化的一个反向运算，对于一个像素点，当我们要把它反池化到$2 * 2$的的区域上，我们只需要将其它三个像素以信息值0进行填充。</p>
<center><img src="http://yeshenlin.com/yelin_image/08_paper.jpg"></center>

<p>###训练过程及结果优化</p>
<p>####防止过拟合<br>在我们模型训练结束以后，模型能够很好地对训练数据进行预测，我们称模型对历史数据的预测表现良好，但是当模型去预测新的数据时，模型表现很差，我们称该模型对未来数据表现很差，这就是常见的过拟合现象。因为数据并不满足独立同分布，未来数据的分布可能会发生变化，一旦发生了模型无法适应的变化，模型表现自然变差。因此，在模型的训练过程中，我们需要采取一些策略去防止过拟合的发生，提高模型的泛华能力。<br>在卷积神经网络的训练过程中，常见的防止过拟合的方法有数据增强、正则化和Dropout等。<br>图像增强的主要方法是：</p>
<ol>
<li>数据集中所有的图像进行上下和左右翻转。</li>
<li>将图像整体像素进行平移若干像素点，移动后的像素点并不影响图像的语义内容。</li>
</ol>
<p>通过以上两种图像增强的方法，图像训练集的数量能够扩充8倍。<br>在训练集不够大的时候，模型在训练的过程中很容易出现过拟合现象，一种简单有效地通过修改模型儿防止过拟合的方法就是Dropout策略。Dropout策略已经是目前深度学习中最为常用的方法之一。Drop的原理就是每次在卷积过程中随机丢弃部分模型参数，从而可以提高模型的鲁棒性。Dropout一般加在全连接层之后，因为全连接层的模型参数占整个模型网络参数的绝大部分，因此全连接层最容易导致过拟合。</p>
<h4 id="二阶段训练法"><a href="#二阶段训练法" class="headerlink" title="二阶段训练法"></a>二阶段训练法</h4><p>由于VGG-net的网络比较深，模型比较复杂，因此在训练分割模型时，迭代收敛会很慢，实验过程比较消耗时间。并且在模型收敛的过程中容易陷入局部最优解，从而模型在并未达到最优的情况下，损失已经停止收敛。这种模型在进行测试集评估的时候，精度比较差。</p>
<p>本文在对全卷积网络进行训练时，采用了二阶段训练法。首先在训练集中挑选出2000张图像作为第一批训练集，该训练集的图像在从分割的角度来看相对比较简单，具有前景单一，对比度高，分割难度小等特点。因此第一批训练集收敛比较快。在第一批数据集的模型收敛好以后，可以将模型保存下来。然后把全集当做第二批数据集，把前者训练好的模型参数用来初始化第二次训练的参数，然后开始训练。这样做的好处是，能够让模型快速收敛，节省训练时间。</p>
<blockquote>
<blockquote>
<p>插入几张第一批数据集，第二批数据集</p>
</blockquote>
</blockquote>
<p>整个二阶段训练的法的流程图如下图所示，通过这种训练方式，一般会得到更好的训练效果。</p>
<p><img src="./1505459910700.png" alt="Alt text"></p>
<h3 id="本章小结-1"><a href="#本章小结-1" class="headerlink" title="本章小结"></a>本章小结</h3><p>本章首先介绍了全卷积神经网络与卷积神经网络的区别，其次深入研究反卷积层与反池化层的在卷积过程中的原理以及起到的作用。为了使用卷积神经网络得到与原图大小一致的图像分割结果，在网络结构中引入了反卷积和反池化。本章最后介绍了防止过拟合的方法以及二阶段训练法。</p>
<h2 id="第3章-结合全卷积神经网络和边缘检测的图像分割"><a href="#第3章-结合全卷积神经网络和边缘检测的图像分割" class="headerlink" title="第3章 结合全卷积神经网络和边缘检测的图像分割"></a>第3章 结合全卷积神经网络和边缘检测的图像分割</h2><p>基于阈值的图像分割有着广泛的应用，合适的阈值可以辅助确定良好的边缘。全卷积神经网络使用卷积层提取的特征反卷积到原图一致大小，从而生成图像分割结果。卷积过程中使用的池化层会丢弃一些像素点信息，这些像素点最终会影响到图像分割的边缘。本章提出了基于边缘检测和全卷积神经网络的最佳阈值寻找算法，能够帮助寻找合适的阈值精确边缘分割。</p>
<h3 id="引言-1"><a href="#引言-1" class="headerlink" title="引言"></a>引言</h3><p>全卷积神经网络随着卷积层数的增加，丢失的边缘信息越来越严重。经过研究发现，在第三个池化层提取的特征的边缘轮廓优于第四个池化层提取的特征的边缘轮廓，以此类推，第四个池化层提取的特征的边缘轮廓优于第五个池化层提取的特征的边缘轮廓。因为池化层在池化过程中，为了达到降低维度的效果，会把一个区域的像素点信息用一个像素点代替。池化丢失的部分像素点的像素值信息最终造成了图像分割边缘模糊的问题。<br><img src="./1505521679480.png" alt="Alt text"><br><img src="./1505521707708.png" alt="Alt text"><br><img src="./1505521725288.png" alt="Alt text"></p>
<h3 id="全卷积网络池化层的特征融合"><a href="#全卷积网络池化层的特征融合" class="headerlink" title="全卷积网络池化层的特征融合"></a>全卷积网络池化层的特征融合</h3><p>如上文所述，在全卷积神经网络的结构中，后面的池化层比前面的池化层提取的原图特征丢失更加严重，但是后面池化层在特征提取上更占有优势。在不丢失足够多原图边缘信息且提取有效特征，全卷积神经网络采用融合的方式来解决这个问题。</p>
<p>如下图所示，FCN-8s、FCN-16s和FCN-32s的图像分割表现依次降低。FCN-8s是全卷积网络第三个池化层提取出的特征图，该特征边缘轮廓相较于后两者损失较少，但是也是有部分边缘信息的损失。在全卷积网络端到端的过程里，只有原图完全保留住所有边缘信息。FCN-32s是原图缩小32倍的特征，对该特征进行反卷积和一次上采样，就能得到与FCN-16s一致大小的特征图。把上采样的特征图与FCN-16s的特征图进行融合，在此进行反卷积和上采样得到与FCN-8s一只大小的特征图。此时在把上采样得到的特征图与FCN-8s的特征图进行融合，得到新的特征图。最后把这个特征图反卷积和上采样直到得到与原图一致大小的特征。<br><img src="./1505516638622.png" alt="Alt text"></p>
<h3 id="边缘检测的概念"><a href="#边缘检测的概念" class="headerlink" title="边缘检测的概念"></a>边缘检测的概念</h3><p>边缘检测的目的就是标识数字图像中亮度变化明显的点，因为图像颜色信息变化明显通常表示附近的像素点有重要变化。这些变化包括表面上的不连续、深度上的<br>不连续或者场景照明变化等。</p>
<p><img src="./1505525213843.png" alt="Alt text"></p>
<p>图像的边缘检测能后快速获取图像的边缘信息，且大幅度地减少了数据量，剔除了可以认为并不相关的其它信息，保留住了图像的结构属性。常见的边缘检测算子主要分为一阶检测算子和二阶检测算子。</p>
<ul>
<li>一阶： Sobel算子，Canny算子，Roberts Cross算子</li>
<li>二阶：Laplacian算子，Marr-Hildreth算子</li>
</ul>
<p>Canny算子是最常用的边缘检测算子，本章使用Canny检测算子检测图像边缘。边缘检测算子用于图像分割最大的弊端是检测过细问题，由于只是利用了像素之间的梯度变化信息没有考虑到空间信息，因此基于边缘检测的图像分割很容易造成过分割。</p>
<h3 id="阈值分割的概念"><a href="#阈值分割的概念" class="headerlink" title="阈值分割的概念"></a>阈值分割的概念</h3><p>阈值分割是一种常用的图像分割方法，如果图像前后景灰度差距越大，阈值分割表现会更加良好。最长用的阈值分割是图像二值化。一般情况下，图像阈值分割的主要任务就是确定图像中像素点应该属于目标区域还是属于背景区域，从而产生分割边缘比较明显的二值化图像。</p>
<p><img src="./1505526945403.png" alt="Alt text"></p>
<p>阈值分割最大的难点是寻找一个合适的分割阈值。虽然目前已经有自适应阈值分割算法，但是当图像复杂，噪声严重的情况下，阈值分割的误差会比较大。而且基于阈值的图像分割算法无法分割多目标的图像。</p>
<h3 id="基于边缘检测和全卷积神经网络的最佳阈值寻找算法"><a href="#基于边缘检测和全卷积神经网络的最佳阈值寻找算法" class="headerlink" title="基于边缘检测和全卷积神经网络的最佳阈值寻找算法"></a>基于边缘检测和全卷积神经网络的最佳阈值寻找算法</h3><p>基于全卷积神经网络的图像分割本质上是将N类分类转化为N个二类分类问题。对于N类的图像分割问题，基于阈值的图像分割算法没法适应这种情况。全卷积神经网络反卷积和上采样结束后，一共提取到N个与原图一致大小的特征，每一个特征图李只有一个前景物体，其它都是背景物体。因此，每一个特征图都是一个可以做阈值分割的图像。</p>
<p>特征图的前景区域亮度比较高，置信度接近于1。背景区域亮度值很暗，置信度接近于0。特征图中每一个像素点的亮度值代表着该像素点隶属于前景还是背景的概率。边缘区域的亮度存在一个渐变的过程，基于阈值的图像分割只在像素信息变化剧烈的情况下表现良好。因此需要一个能够辅助寻找一个精确分割边缘的办法。</p>
<p>边缘检测能保留住原图像中所有的边缘信息，通过边缘检测算子检测到的图像边缘与全卷积神经网络提取到的特征相结合，可以寻找到最佳阈值。通过最佳阈值就能把每一个特征图中的模糊边缘上的像素点进行精确分类。</p>
<p><img src="./1505527886197.png" alt="Alt text"><br><img src="./1505527903270.png" alt="Alt text"></p>
<p>基于边缘检测和全卷积神经网络的最佳阈值寻找算法流程如下：<br>a） 使用canny算子对原图进行边缘检测得到图像的边缘检测；<br>b） 假设是一个N类别的图像分割问题，使用训练好的全卷积神经网络对原图进行特征提取，一共提取到N个特征图；<br>c）  设置两个分割阈值分别是$\alpha_1$ = 0.1和$\alpha_2$  = 0.9<br>c）  遍历特征图像所有的像素点，像素点分类概率用$p(x,y)$表示。如果$p(x,y)$ &lt; $\alpha_1$,则$p(x,y) = 0$, 如果$p(x,y)$ &gt; $\alpha_2$,则$p(x,y) = 1$<br>d） 假设边缘检测得到的特征图为A，全卷积得到的特征图为B。对于B中$p(x,y) == 0 $ 或者$p(x,y) == 1$的点，在A中$(x,y)$所在位置像素值置为0。直到所有的像素点都经过匹配，A只留下了部分有效的边缘；<br>e） 对A中留下的有效边缘一次遍历得到位置$(x,y)$, 找到B中国$(x,y)$对应点的像素值。把所有能匹配到的点的像素值求加权平均，即为最佳阈值；<br>f） 使用最佳阈值对B进行阈值分割，得到最终结果。</p>
<blockquote>
<blockquote>
<p>这里需要画出流程图，以及补充几个公式</p>
</blockquote>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本章首先介绍了全卷积神经网络分割边缘模糊的原因是池化层丢失了边缘信息造成的，然后介绍了全卷积神经网络采用多层池化层特征融合的方式来解决这个边缘信息丢失的问题。但是特征融合并不能补回所有的边缘信息，边缘模糊的问题依然存在。接下来介绍了边缘检测与阈值分割的概念，最后提出了基于边缘检测和全卷积神经网络的最佳阈值寻找算法，是分割后的图像边缘更加精确。</p>
<h2 id="第4章-结合全卷积神经网络和K-means聚类算法的图像分割"><a href="#第4章-结合全卷积神经网络和K-means聚类算法的图像分割" class="headerlink" title="第4章 结合全卷积神经网络和K-means聚类算法的图像分割"></a>第4章 结合全卷积神经网络和K-means聚类算法的图像分割</h2><p>本章主要介绍结合全卷积神经网络和K-means聚类算法的图像分割方法。由于全卷积神经网络在卷积过程中会丢失部分边缘信息，因此在卷积层的提取出的特征图的边缘部分会出现概率值模糊的现象。本章首先分析全卷积神经网络在图像分割中边缘分割上的不足，然后提出用K-means聚类算法对输入图像进行过分割，对过分割后的图像与全卷积神经网络提取到的特征图像进行匹配，对全卷积过程中丢失的边缘信息进行补充。</p>
<h3 id="引言-2"><a href="#引言-2" class="headerlink" title="引言"></a>引言</h3><p>全卷积神经网络的前半部分是属于特征提取阶段，后半部分是尺寸还原部分。前半部分都是卷积层和池化层的结合，由于全卷积网络层数较深，且每一阶段的卷积后都会跟随一个池化层。因此经过多次卷积以后，得到的图像越来越小，分辨率相比于原图缩小32倍。反卷积和反池化层的作用就是把这个低分辨率的图像恢复到原图分辨率，一共要进行32倍的上采样过程才能得到与原图一致的大小。那么全卷积网络就会得到一个边缘分割不精细的结果，产生这个的原因就是上采样的过程。<br><img src="./1505462384527.png" alt="Alt text"><img src="./1505462409001.png" alt="Alt text"><br>以上图为例，图1是输入图像，图2是1/8卷积得到的分割结果，图3是上采样得到与原图一致大小的分割结果。从图中热图可以看到图像的边缘分割比较模糊，从前景的中间到前景的边缘部分，概率的值层次感比较明显，说明越到边缘部分，网络模型越难以准确地将像素点的分配到对应的标签。经过研究，造成这个问题的主要原因就是在卷积过程中，池化层在降低维度的同时，会丢失原图部分的边缘轮廓信息，虽然在全卷积的后半部分尝试使用反卷积区恢复原图尺寸，但是基于双线性插值的办法始终无法补全原图丢失的信息。为了克服这个问题，需要使用额外的方法来拉动原图边缘上模糊的像素点向正确的标签上进行归类。本文使用K-means聚类算法对图像进行过分割，根据图像中把原图像分割成不同大小不同颜色的区域。然后通过这些小区域的边缘区补充全卷积神经网络在卷积过程中丢失的边缘信息。</p>
<h3 id="K-means聚类算法的图像分割"><a href="#K-means聚类算法的图像分割" class="headerlink" title="K-means聚类算法的图像分割"></a>K-means聚类算法的图像分割</h3><p>图像分割的本质就是把图像中的像素点分类到不同的类别中。有很多不同聚类算法被用到了图像分割中，其中使用最流行的就是K-means聚类算法。K-means聚类算法是无监督聚类算法，它是一种简单且快速的分割算法，而且它可以用于大量的变量。由于输入的聚类中心的个数的不同，K-means算法产生的聚类结果也会相应变化。</p>
<p>k-means算法是一种机遇距离相似性度量的聚类算法，通过比较数据集样本之间的多维空间中的相似性，将样本划分不到不同的类别。K-means聚类算法主要由两个单独的阶段组成。在第一阶段，计算K个聚类中心；第二阶段，把所有的像素点分类到离它最近的那个聚类中心。有很多不同的方法来定义目标点到聚类中心的距离，最常用的方法之一是欧氏距离。一旦分组完成，k-menas算法会重新计算聚类中心，在每一个聚类中心和每一个像素点之间计算一个新的欧氏距离。最后的聚类结果中，每一个类别都是由聚类中心及其成员对象组成。每一个聚类中的像素点到其聚类中心之和都被最小化。因此K-means是一种迭代算法，跌倒的目的就是最小化每一个聚类中所有像素点到该 聚类中心的欧氏距离的总和。</p>
<p>K-means聚类算法用在彩色图像像素分类中，需要计算像素点在RGB三通道像素值上的欧式距离。假设我们要对大小为$x * y$的图像划分到k个聚类中。$p(x, y)$表示待分类目标像素，$c_k$表示聚类中心。那么K-means算法的流程如下所示：</p>
<ol>
<li>初始化k个聚类中心</li>
<li>对输入图像中的每一个像素点，计算每一个像素点到每一个聚类中心之间的相似度</li>
<li>将像素点划分到离自己最近的聚类中心所在的类别</li>
</ol>
<p><img src="./1505472905532.png" alt="Alt text"></p>
<p>4.直到所有的像素点都被分类， 重新计算每个类别中所有的像素的RGB三通道像素值的均值，并把该均值作为此类别聚类的聚类中心。</p>
<p><img src="./1505472994048.png" alt="Alt text"></p>
<ol>
<li>重复以上步骤直到误差达到可容忍误差以下。</li>
</ol>
<p>下图展示了K-means聚类算法的详细流程，由图（1）到图（9）展示的聚类中心变化可以看到，在迭代的过程中，聚类中心最终稳定在两个聚类的中间。所有的样本点也分类到离它最近的聚类中心所在的类别。</p>
<p><img src="./1505474092037.png" alt="Alt text"></p>
<p>下图展示了基于K-means聚类算法对彩色图像进行分割的结果。可以看到经过K-means对RGB三通道图像进行聚类后，原彩色图像被分割成了多个不同颜色的区域，相邻的区域之间并不重叠，虽然粒度过细，但是边缘信息保存得比较好。全卷积神经网络分割的结果特点是整体分割较好，前景物体整理分割完整，但是边缘信息保留不够。因此，本章提出使用K-means聚类算法来为全卷积神经网络补充卷积过程中丢失的边缘信息，从而克服全卷积神经网络分割边缘模糊的难点。</p>
<p><img src="./1505473957976.png" alt="Alt text"></p>
<h3 id="结合全卷积神经网络和K-means聚类算法的图像分割算法"><a href="#结合全卷积神经网络和K-means聚类算法的图像分割算法" class="headerlink" title="结合全卷积神经网络和K-means聚类算法的图像分割算法"></a>结合全卷积神经网络和K-means聚类算法的图像分割算法</h3><p>全卷积神经网络存在边缘分割模糊的弱点，边缘像素点的概率并没有处于趋于0或1，分类器在分类的时候容易将前景的像素点错分到背景或者将背景像素点错分到前景。从特征图中可以观察到，前景物体的主要区域的亮度值比较高，即分类到某一个类的置信度比较高。边缘部分的亮度值渐渐变暗，缓缓与背景的亮度靠近，这些亮度值从前景到背景的像素点都属于分类置信度不够高的情况。分类器能把置信度接近1的像素点都分类为前景，同理，把置信度接近于0的像素点分类为背景。对于边缘部分的像素点，如果此时分类器强行分类，就会造成误分类。</p>
<blockquote>
<blockquote>
<p>这里需要一张前景分割边缘模糊的图片和一张背景分割边缘模糊的图片</p>
</blockquote>
</blockquote>
<p>K-means的图像分割性能远不及全卷积神经网络，因为K-means不能像全卷积神经网络那样，自动地推断出图像中前景物体的类别个数并将每一个前景物体单独作为一个整体的区域分割出来。K-means的聚类个数依赖于人工设定，然而现实应用中，每一张图像的内容都不一样，因此对于每一张图像都人为地去设定一个聚类个数K是一件难以实现的操作。因此，K-means聚类算法很容易出现过分割的情况，把一个前景物体分割成了多个不同的子区域。K-means算法相较于全卷积神经网络在图像分割边缘上有着明显的优势。K-means算法在进行彩色图像聚类的时候，是居于RGB3通道的欧氏距离来判断图像中像素点的相似度，因此分割结果中同一个分割区域中的像素点的颜色信息更接近。如果K值越大，则同一个区域中像素点的颜色平均相似度更高。</p>
<p>这里，我们提出K-means分割彩色图像后保留的良好的分割边缘来补充全卷积神经网络在卷积过程中丢失的边缘信息。首先，K-means是实现最为简单且效率高的聚类算法，且边缘保持良好。其次，K-means容易产生过分割，适度的过分割对于补充全卷积神经网络边缘信息更加有益。</p>
<p>结合全卷积神经网络和K-means聚类算法的图像分割算法流程如下：<br>阶段一、使用K-means算法对原图像进行区域分割：<br>a） 设置聚类参数K；<br>b )  初始化K个聚类中心；<br>c） 对原图像中的每一个像素点，分别计算像素点与所有聚类中心的相似度<br>d） 将像素点划分到与自己相似度最高的那个聚类中心所在的类别；<br>e )   直到所有的像素点被分完类，然后重新计算每一个聚类中所有像素点的特征均值，然后将该特征均值设为该聚类新的聚类中心；<br>f）  重复以上步骤直到分割误差达到可容忍误差以下。<br>阶段二、使用全卷积神经网络对图像进行特征提取：<br>g )  把原图像输入到已经训练好的全卷积神经网络模型中;<br>h )   分别提取第一阶段卷积输出的1/8原图大小的特征、第二阶段卷积输出的1/16原图大小的特征和第三阶段卷积输出的1/32原图大小的特征;<br>i  )  把1/32原图尺寸的特征图反卷积的结果与1/16原图尺寸的特征图进行特征融合，得到新的1/16原图尺寸的特征图，然后将该特征图反卷积得到的结果与1/8原图尺寸的特征进行特征融合得到新的1/8原图尺寸的特征，最后再进行反卷积，直到生成原图大小一致的特征图；<br>阶段三、对全卷积神经网络提取出的特征进行分段阈值分割：<br>j  )  设置两个分割阈值分别是$\alpha_1$ = 0.1和$\alpha_2$  = 0.9<br>k )  遍历整个图像所有的像素点，像素点分类概率用$p(x,y)$表示。如果$p(x,y)$ &lt; $\alpha_1$,则$p(x,y) = 0$, 如果$p(x,y)$ &gt; $\alpha_2$,则$p(x,y) = 1$<br>阶段四、对特征图上边缘部分的像素点与K-means得到的分割结果进行匹配<br>l）设定K-means聚类算法得到的分割结果为图A，全卷积神经网络经过提取得到的特征经过阈值分割得到的结果为图B。<br>m) 遍历图A中$p(x,y)  !=  0$且$p(x,y)  !=  1$的点，设定当前点在A图中为$A(x_1,y_1)$，找到它在B图中对应的点$B(x_1,y_1)$,从而得到$B(x_1,y_1)$所在聚类的聚类中心$B(x_2,y_2)$,找到A图中的$B(x_2,y_2)$。若$B(x_2,y_2) == 0$,则$A(x_1,y_1) = 0$,否则$A(x_1,y_1) = 1$。</p>
<p>下图展示了结合全卷积神经网络和K-means聚类算法的流程图。通过对两路方法得到的分割结果进行后处理，能够得到更精确的分割结果。这样的改进技能适应复杂背景的自然场景图像，也能对抗噪声较强的图像。<br><img src="./1505498002726.png" alt="Alt text"></p>
<blockquote>
<blockquote>
<p>这里需要插入几张算法结果图</p>
</blockquote>
</blockquote>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>本章首先介绍了全卷积神经网络在图像的边缘分割存在的不足，在卷积过程中池化层会丢失部分原图边缘信息，这些信息不能通过反卷积和反池化来弥补。其次介绍了K-means聚类算法在图像分割中的原理，K-means聚类算法能够在过分割图像的前提下，保持良好的分割边缘，最后本章提出结合全卷积神经网络和K-means聚类算法的图像分割方法。</p>
<h2 id="第5章-实验结果及分析"><a href="#第5章-实验结果及分析" class="headerlink" title="第5章 实验结果及分析"></a>第5章 实验结果及分析</h2><p>本章首先介绍图像分割所采用的数据库，然后介绍图像分割的评价标准。最后通实验来评估本文算法在图像分割中的性能，并与其它的图像分割算法进行比较，包括FCN-32s,FCN-16s,FCN-8s,FCN-ResNet。</p>
<h3 id="数据库介绍"><a href="#数据库介绍" class="headerlink" title="数据库介绍"></a>数据库介绍</h3><p>在图像分割中，各种自然场景下复杂的图像数据库对于训练一个高性能分割模型起着重要作用。本章采用公开的数据库进行实验，评估算法在不同场景下的分割结果。<br>PASCAL VOC2012为图像识别和分类提供了高质量的数据集。该数据集中的所有图片都是自然场景的中图像。物体的类别一共有20类：</p>
<ul>
<li>Person: person</li>
<li>Animal: bird, cow, dog， cat,  sheep, horse</li>
<li>Vehicle: boat, aeroplane, bicycle, bus, motorbike, train, car</li>
<li>Indoor:  potted plant, bottle, dining table,sofa, tv/monitor，chair</li>
</ul>
<p>Paccal VOC2012数据集主要用于三类任务：检测、分割和分割。本文只用该数据集进行图像分割实验。标准训练集有1464张图像，标准测试集有1449张图像，另外有额外的训练图像10582张图像。</p>
<h3 id="评价方法"><a href="#评价方法" class="headerlink" title="评价方法"></a>评价方法</h3><h3 id="实验设计与结果分析"><a href="#实验设计与结果分析" class="headerlink" title="实验设计与结果分析"></a>实验设计与结果分析</h3><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><h2 id="第6章-总结与展望"><a href="#第6章-总结与展望" class="headerlink" title="第6章 总结与展望"></a>第6章 总结与展望</h2><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>图像分割在计算机视觉、自动驾驶、医学图像、卫星图像及机器人技术等领域有着广泛的应用，研究学者们提出了很多优秀的图像分割方法，有基于阈值的分割方法、基于边缘检测的分割方法、基于聚类的分割方法以及本文主要讨论的基于全卷积神经网络的分割方法。自从卷积神经网络进入图像分割领域以来，该算法就受到学者的广泛的关注。本文主要研究的是基于全卷积神经网络的图像分割及边缘优化的研究。文中提出了结合全卷积神经网络和边缘检测的图像分割算法。本文的研究要点主要是如何解决全卷积神经网络在卷积核降采样过程中丢失的部分边缘像素信息而导致的分割边缘模糊的现象。全卷积神经网络把N类目标的分割问题转化为N个二分类问题，在全卷积神经网络反卷积和反池化得到与原图一致大小的特征图上进行阈值分割是一个很好的办法。因此寻找一个合适的阈值是最关键的任务。由于特征图中边缘部分的亮度变换比较平缓，因此无法通过自适应阈值的方式来确定每一个特征图的阈值。最优的阈值应该是图像边缘线上的像素点的亮度值。边缘检测算子可以完美保留原图的边缘轮廓信息，结合全卷积神经网络的特征图与边缘特征图，可以过滤掉无效边缘。剩余的边缘的位置都是包含在全卷积网络特征图中模糊部分，通过对剩余边缘所在位置的亮度值求平均，求出的阈值即是最优阈值。本文提出的另外一个图像分割方法是结合全卷积神经网络和K-means聚类算法的图像分割算法。K-means算法能够将原图像分割成K个不同的聚类，每一个聚类都有一个聚类中心，且同一个聚类中的所有像素点的颜色一样。K-means虽然会在K值选取不当的时候产生严重的过分割，但是它能够完整保持图像的完整边缘，在边缘部分分割精确。通过K-means过分割后的结果去补充全卷积神经网络卷积过程中丢失的边缘信息可以提高图像分割精度。</p>
<p>本文的主要贡献如下：<br>1）针对自然场景图像，使用全卷积神经网络分割模型。采用两阶段的模型训练方法，训练并优化模型。直接对自然场景图像在像素水平上进行预测其所属的语义类别。全卷积网络是仅有卷积层和反卷积层的网络模型，卷积层用于提取分割特征，反卷积层把分割特征恢复到原图一致大小。在图像分割领域，全卷积网络被证明能达到较好的分割效果。</p>
<p>2） 提出了结合全卷积神经网络和边缘检测的图像分割算法：通过边缘检测来辅助寻找最优分割阈值，用最优阈值去分割全卷积网络反卷积和上采样后提取的特征图。通过这种方式补充卷积过程中丢失的边缘信息能够提高分割精度。</p>
<p>3） 提出了结合全卷积神经网络和K-means聚类算法的图像分割算法：通过K-means算法产生过分割后的图像，使用过分割图像的边缘和聚类中心重新判断全卷积神经网络反卷积和上采样后提取的特征图中模糊的边缘区域。通过这种方式把置信度角度的像素点结合空间信息重新进行分类，在一定程度上补充了原图的边缘信息，可以达到分割边缘优化的作用。</p>
<p>4） 将本文提出的算法模型应用到人体分割领域。使用两阶段训练法，训练并优化模型，把模型应用于人体图像，取得了接近真值的效果。</p>
<h3 id="未来工作展望"><a href="#未来工作展望" class="headerlink" title="未来工作展望"></a>未来工作展望</h3><p>本文针对的基于全卷积神经网络图像分割边缘优化的研究存在诸多值得改进的地方，可以在未来把研究集中在以下几个方面：<br>1） 本文提出的结合全卷积神经网络和K-means聚类算法的图像分割方法中，K-means聚类算法对彩色图像进行分割时，对于不同的K值，分割结果差异很大。当K-means分割得到的色块大小比全卷积神经网络提取的特征图中模糊区域小时，很容易出现该色块聚类中心和目标像素点同时都属于模糊区域。此时，需要寻找第二临近的聚类中心，无疑增大了算法的时间复杂度。因此，可以尝试使用效果更好地聚类算法对原图像进行分割。</p>
<p>2） 本文提出的两种图像分割方法都是针对分割边缘进行优化。两种方法都是在对全卷积神经网络反卷积和上采样后提取的特征图进行后处理。因此后期研究可以尝试将后处理过程融入到卷积神经网络中，形成一个真正意义上的端到端系统。</p>
<p>3） 本文提出的两种边缘优化分割算法都是使用原图信息来补充全卷积神经网络在降采样过程中丢失的边缘轮廓信息，从而提高分类精度。后期研究可以尝试其它方法补充丢失的边缘轮廓信息，例如马尔科夫随机场或者条件随机场等概率图模型。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>时光飞逝，转眼间两年半的研究生生活就要结束了。回想两年前刚踏入研究生大门的时候，充满喜悦和期待，转眼间将走完这段旅程，心中感慨万千。在即将毕业之际，感谢陪我度过美好时光的每一个尊敬的老师和师弟和同学，正是你们的帮助，我才能解决疑惑，直到学业的顺利弯成。</p>
<p>首先我要感谢我的导师文颖老师，感谢她在科研和生活上对我的帮助。文老师在科研上认真严谨，每次在开实验室组会，总是认真听我们汇报，然后给出针对性地意见，指明研究方向。无论任何时候，悉心指导督促我们进步。在我研究中遇到苦难停止不前时，文老师和我一起讨论改进方向。在文老师的帮助下，最终解决了这个问题，才能完成论文的研究。文老师在学术研究上有着严谨治学的态度，经常教育我们读论文要抓住文章的重点，学习文章的优点，督促我们每周汇报所读论文，给研究打下坚实的基础。文老师经常教育我们动手去做，看到好的论文、方法，动手去实现，不要眼高手低，只看不做不能深入理解一件事情。在生活上，文老师给我和实验室的师弟们无微不至的关怀。文老师开阔的视野、精益求精的工作作风，深深地感染和激励着我，在此谨向文老师致以衷心的感谢和崇高的敬意。</p>
<p>其次要感谢实验室的师兄张乐师兄和师弟们，一起营造了良好的科研氛围。经常一起讨论学术问题，让我收获很多，一起组织娱乐活动，给实验室带来了欢乐和成长。</p>
<p>最后感谢我的父母和家人，这么多年以来对我的支持和鼓励，让我更加乐观的面对生活中的一切，让我在前进的道路上充满动力和勇气。</p>
<p>由衷地感谢参与我硕士毕业工作的所有老师以及本文的评审老师，你们辛苦了。</p>
<h2 id="攻读硕士学位期间的研究成果"><a href="#攻读硕士学位期间的研究成果" class="headerlink" title="攻读硕士学位期间的研究成果"></a>攻读硕士学位期间的研究成果</h2>
      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">分享</a>
        </div>
        
  
  <div class="categories">
    <a href="/categories/技能树/">技能树</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/图像分割/">图像分割</a>, <a href="/tags/深度学习/">深度学习</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><a href="/categories/Java/">Java</a><small>3</small></li>
  
    <li><a href="/categories/个人生活/">个人生活</a><small>3</small></li>
  
    <li><a href="/categories/兴趣爱好/">兴趣爱好</a><small>2</small></li>
  
    <li><a href="/categories/技能树/">技能树</a><small>1</small></li>
  
    <li><a href="/categories/算法/">算法</a><small>3</small></li>
  
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">最新文章</h3>
  <ul class="entry">
    
      <li>
        <a href="/2017/09/27/小孩子的不快活/">小孩子的不快活</a>
      </li>
    
      <li>
        <a href="/2017/09/27/明日又天涯/">明日又天涯</a>
      </li>
    
      <li>
        <a href="/2017/09/06/2017-9-6/">2017-9-6</a>
      </li>
    
      <li>
        <a href="/2017/09/04/2017-9-4/">2017-9-4</a>
      </li>
    
      <li>
        <a href="/2017/09/02/2017-9-2/">2017-9-2</a>
      </li>
    
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/JVM/">JVM</a><small>3</small></li>
  
    <li><a href="/tags/Java/">Java</a><small>3</small></li>
  
    <li><a href="/tags/三毛/">三毛</a><small>1</small></li>
  
    <li><a href="/tags/图像分割/">图像分割</a><small>1</small></li>
  
    <li><a href="/tags/字符串/">字符串</a><small>1</small></li>
  
    <li><a href="/tags/徐志摩/">徐志摩</a><small>1</small></li>
  
    <li><a href="/tags/排序/">排序</a><small>1</small></li>
  
    <li><a href="/tags/日记/">日记</a><small>3</small></li>
  
    <li><a href="/tags/深度学习/">深度学习</a><small>1</small></li>
  
    <li><a href="/tags/链表/">链表</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">标签云</h3>
  <div class="entry">
    <a href="/tags/JVM/" style="font-size: 20px;">JVM</a> <a href="/tags/Java/" style="font-size: 20px;">Java</a> <a href="/tags/三毛/" style="font-size: 10px;">三毛</a> <a href="/tags/图像分割/" style="font-size: 10px;">图像分割</a> <a href="/tags/字符串/" style="font-size: 10px;">字符串</a> <a href="/tags/徐志摩/" style="font-size: 10px;">徐志摩</a> <a href="/tags/排序/" style="font-size: 10px;">排序</a> <a href="/tags/日记/" style="font-size: 20px;">日记</a> <a href="/tags/深度学习/" style="font-size: 10px;">深度学习</a> <a href="/tags/链表/" style="font-size: 10px;">链表</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  <p>
  
  &copy; 2017 Now You See Me!
  
  All rights reserved.</p>
  <p>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></p>
</div>
<div class="clearfix"></div>

<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script></footer>
  <script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id='bg'></div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>